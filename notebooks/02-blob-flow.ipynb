{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Analysis of blob flow through validators, builders, and relays on Ethereum mainnet."
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "target_date = None  # Set via papermill, or auto-detect from manifest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.colors as pc\n",
        "\n",
        "from loaders import load_parquet\n",
        "\n",
        "MIN_BLOCKS = 10  # Minimum blocks for entity filtering"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load blob flow data\n",
        "df_proposer_blobs = load_parquet(\"proposer_blobs\", target_date)\n",
        "\n",
        "# Fill missing values\n",
        "df_proposer_blobs[\"proposer_entity\"] = df_proposer_blobs[\"proposer_entity\"].fillna(\"Unknown\")\n",
        "df_proposer_blobs[\"winning_relay\"] = df_proposer_blobs[\"winning_relay\"].fillna(\"Local/Unknown\")\n",
        "\n",
        "print(f\"Total blocks: {len(df_proposer_blobs)}\")\n",
        "print(f\"Unique proposer entities: {df_proposer_blobs['proposer_entity'].nunique()}\")\n",
        "print(f\"Unique relays: {df_proposer_blobs['winning_relay'].nunique()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Proposer Entity -> Blob Count\n",
        "\n",
        "Sankey diagram showing how different staking entities (pools, solo stakers) distribute their blocks across blob counts. Wider flows indicate more blocks. Entities with fewer than 10 blocks are filtered out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate block counts per entity\n",
        "entity_block_counts = df_proposer_blobs.groupby(\"proposer_entity\").size()\n",
        "\n",
        "# Get entities that meet the threshold\n",
        "valid_entities = entity_block_counts[entity_block_counts >= MIN_BLOCKS].index\n",
        "\n",
        "# Filter the dataframe\n",
        "df_filtered = df_proposer_blobs[df_proposer_blobs[\"proposer_entity\"].isin(valid_entities)]\n",
        "\n",
        "entity_blob_flow = (\n",
        "    df_filtered.groupby([\"proposer_entity\", \"blob_count\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"block_count\")\n",
        ")\n",
        "\n",
        "# Sort entities by total block count (descending)\n",
        "entity_totals = entity_blob_flow.groupby(\"proposer_entity\")[\"block_count\"].sum()\n",
        "entities = entity_totals.sort_values(ascending=False).index.tolist()\n",
        "blob_counts = sorted(entity_blob_flow[\"blob_count\"].unique(), reverse=True)  # Descending\n",
        "\n",
        "# Create node labels: entities + blob counts (blob counts sorted descending)\n",
        "entity_nodes = [f\"E:{e}\" for e in entities]\n",
        "blob_nodes = [f\"{int(bc)} blobs\" for bc in blob_counts]\n",
        "all_nodes = entity_nodes + blob_nodes\n",
        "\n",
        "# Create mapping from name to index\n",
        "node_map = {name: idx for idx, name in enumerate(all_nodes)}\n",
        "\n",
        "# Define x and y positions for nodes\n",
        "n_entities = len(entity_nodes)\n",
        "n_blobs = len(blob_nodes)\n",
        "\n",
        "# Create color gradient for blob nodes (higher blob count = darker)\n",
        "max_blob = max(blob_counts)\n",
        "min_blob = min(blob_counts)\n",
        "blob_colors = [\n",
        "    pc.sample_colorscale(\"Amp\", (bc - min_blob) / (max_blob - min_blob) if max_blob > min_blob else 0.5)[0]\n",
        "    for bc in blob_counts\n",
        "]\n",
        "entity_colors = [pc.qualitative.Plotly[i % len(pc.qualitative.Plotly)] for i in range(n_entities)]\n",
        "\n",
        "x_pos = []\n",
        "y_pos = []\n",
        "\n",
        "# Entity nodes on the left (x=0.01)\n",
        "for i in range(n_entities):\n",
        "    x_pos.append(0.01)\n",
        "    y_pos.append((i + 0.5) / n_entities)\n",
        "\n",
        "# Blob count nodes on the right (x=0.99), evenly spaced vertically (descending order)\n",
        "for i in range(n_blobs):\n",
        "    x_pos.append(0.99)\n",
        "    y_pos.append((i + 0.5) / n_blobs)\n",
        "\n",
        "sources = []\n",
        "targets = []\n",
        "values = []\n",
        "\n",
        "for _, row in entity_blob_flow.iterrows():\n",
        "    e_node = f\"E:{row['proposer_entity']}\"\n",
        "    bc_node = f\"{int(row['blob_count'])} blobs\"\n",
        "    if e_node in node_map and bc_node in node_map:\n",
        "        sources.append(node_map[e_node])\n",
        "        targets.append(node_map[bc_node])\n",
        "        values.append(row[\"block_count\"])\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Sankey(\n",
        "            arrangement=\"snap\",\n",
        "            node=dict(\n",
        "                pad=15,\n",
        "                thickness=20,\n",
        "                line=dict(color=\"black\", width=0.5),\n",
        "                label=all_nodes,\n",
        "                x=x_pos,\n",
        "                y=y_pos,\n",
        "                color=entity_colors + blob_colors,\n",
        "            ),\n",
        "            link=dict(source=sources, target=targets, value=values),\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "fig.update_layout(\n",
        "    title=\"Blob flow: Proposer Entity -> Blob Count\",\n",
        "    font_size=12,\n",
        "    width=800,\n",
        "    height=3500,\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Relay -> Blob Count\n",
        "\n",
        "Shows which MEV-boost relays are associated with different blob counts. Reveals whether certain relays tend to produce blocks with more or fewer blobs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "relay_blob_flow = (\n",
        "    df_proposer_blobs.groupby([\"winning_relay\", \"blob_count\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"block_count\")\n",
        ")\n",
        "\n",
        "# Sort relays by total block count (descending)\n",
        "relay_totals = relay_blob_flow.groupby(\"winning_relay\")[\"block_count\"].sum()\n",
        "relays = relay_totals.sort_values(ascending=False).index.tolist()\n",
        "\n",
        "blob_counts = sorted(relay_blob_flow[\"blob_count\"].unique(), reverse=True)  # Descending\n",
        "\n",
        "# Create node labels: relays + blob counts (blob counts sorted descending)\n",
        "relay_nodes = [f\"R:{r}\" for r in relays]\n",
        "blob_nodes = [f\"{int(bc)} blobs\" for bc in blob_counts]\n",
        "all_nodes = relay_nodes + blob_nodes\n",
        "\n",
        "# Create mapping from name to index\n",
        "node_map = {name: idx for idx, name in enumerate(all_nodes)}\n",
        "\n",
        "# Define x and y positions for nodes\n",
        "n_relays = len(relay_nodes)\n",
        "n_blobs = len(blob_nodes)\n",
        "\n",
        "# Create color gradient for blob nodes (higher blob count = darker)\n",
        "max_blob = max(blob_counts)\n",
        "min_blob = min(blob_counts)\n",
        "blob_colors = [\n",
        "    pc.sample_colorscale(\"Amp\", (bc - min_blob) / (max_blob - min_blob) if max_blob > min_blob else 0.5)[0]\n",
        "    for bc in blob_counts\n",
        "]\n",
        "relay_colors = [pc.qualitative.Pastel[i % len(pc.qualitative.Pastel)] for i in range(n_relays)]\n",
        "\n",
        "x_pos = []\n",
        "y_pos = []\n",
        "\n",
        "# Relay nodes on the left (x=0.01)\n",
        "for i in range(n_relays):\n",
        "    x_pos.append(0.01)\n",
        "    y_pos.append((i + 0.5) / n_relays)\n",
        "\n",
        "# Blob count nodes on the right (x=0.99), evenly spaced vertically (descending order)\n",
        "for i in range(n_blobs):\n",
        "    x_pos.append(0.99)\n",
        "    y_pos.append((i + 0.5) / n_blobs)\n",
        "\n",
        "sources = []\n",
        "targets = []\n",
        "values = []\n",
        "\n",
        "for _, row in relay_blob_flow.iterrows():\n",
        "    r_node = f\"R:{row['winning_relay']}\"\n",
        "    bc_node = f\"{int(row['blob_count'])} blobs\"\n",
        "    if r_node in node_map and bc_node in node_map:\n",
        "        sources.append(node_map[r_node])\n",
        "        targets.append(node_map[bc_node])\n",
        "        values.append(row[\"block_count\"])\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Sankey(\n",
        "            arrangement=\"snap\",\n",
        "            node=dict(\n",
        "                pad=15,\n",
        "                thickness=20,\n",
        "                line=dict(color=\"black\", width=0.5),\n",
        "                label=all_nodes,\n",
        "                x=x_pos,\n",
        "                y=y_pos,\n",
        "                color=relay_colors + blob_colors,\n",
        "\n",
        "            ),\n",
        "            link=dict(source=sources, target=targets, value=values),\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "fig.update_layout(\n",
        "    title=\"Blob flow: Relay -> Blob Count\",\n",
        "    font_size=12,\n",
        "    height=900,\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Proposer Entity -> Relay\n",
        "\n",
        "Maps which staking entities use which relays. Shows the relationship between validators and the MEV-boost relay infrastructure they rely on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate block counts per entity\n",
        "entity_block_counts = df_proposer_blobs.groupby(\"proposer_entity\").size()\n",
        "valid_entities = entity_block_counts[entity_block_counts >= MIN_BLOCKS].index\n",
        "\n",
        "# Filter the dataframe\n",
        "df_filtered = df_proposer_blobs[df_proposer_blobs[\"proposer_entity\"].isin(valid_entities)]\n",
        "\n",
        "proposer_relay_flow = (\n",
        "    df_filtered.groupby([\"proposer_entity\", \"winning_relay\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"block_count\")\n",
        ")\n",
        "\n",
        "# Sort entities by total block count (descending)\n",
        "entity_totals = proposer_relay_flow.groupby(\"proposer_entity\")[\"block_count\"].sum()\n",
        "entities = entity_totals.sort_values(ascending=False).index.tolist()\n",
        "\n",
        "# Sort relays by total block count (descending)\n",
        "relay_totals = proposer_relay_flow.groupby(\"winning_relay\")[\"block_count\"].sum()\n",
        "relays = relay_totals.sort_values(ascending=False).index.tolist()\n",
        "\n",
        "# Create node labels: entities + relays\n",
        "entity_nodes = [f\"E:{e}\" for e in entities]\n",
        "relay_nodes = [f\"R:{r}\" for r in relays]\n",
        "all_nodes = entity_nodes + relay_nodes\n",
        "\n",
        "# Create mapping from name to index\n",
        "node_map = {name: idx for idx, name in enumerate(all_nodes)}\n",
        "\n",
        "# Define x and y positions for nodes\n",
        "n_entities = len(entity_nodes)\n",
        "n_relays = len(relay_nodes)\n",
        "\n",
        "entity_colors = [pc.qualitative.Plotly[i % len(pc.qualitative.Plotly)] for i in range(n_entities)]\n",
        "relay_colors = [pc.qualitative.Pastel[i % len(pc.qualitative.Pastel)] for i in range(n_relays)]\n",
        "\n",
        "x_pos = []\n",
        "y_pos = []\n",
        "\n",
        "# Entity nodes on the left (x=0.01)\n",
        "for i in range(n_entities):\n",
        "    x_pos.append(0.01)\n",
        "    y_pos.append((i + 0.5) / n_entities)\n",
        "\n",
        "# Relay nodes on the right (x=0.99)\n",
        "for i in range(n_relays):\n",
        "    x_pos.append(0.99)\n",
        "    y_pos.append((i + 0.5) / n_relays)\n",
        "\n",
        "sources = []\n",
        "targets = []\n",
        "values = []\n",
        "\n",
        "for _, row in proposer_relay_flow.iterrows():\n",
        "    e_node = f\"E:{row['proposer_entity']}\"\n",
        "    r_node = f\"R:{row['winning_relay']}\"\n",
        "    if e_node in node_map and r_node in node_map:\n",
        "        sources.append(node_map[e_node])\n",
        "        targets.append(node_map[r_node])\n",
        "        values.append(row[\"block_count\"])\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Sankey(\n",
        "            arrangement=\"snap\",\n",
        "            node=dict(\n",
        "                pad=15,\n",
        "                thickness=20,\n",
        "                line=dict(color=\"black\", width=0.5),\n",
        "                label=all_nodes,\n",
        "                x=x_pos,\n",
        "                y=y_pos,\n",
        "                color=entity_colors + relay_colors,\n",
        "            ),\n",
        "            link=dict(source=sources, target=targets, value=values),\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "fig.update_layout(\n",
        "    title=\"Blob flow: Proposer Entity -> Relay\",\n",
        "    font_size=12,\n",
        "    width=800,\n",
        "    height=3500,\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Proposer Entity -> Relay -> Blob Count\n",
        "\n",
        "Complete three-stage flow: from staking entities through relays to final blob counts. This comprehensive view shows the full pipeline of how blobs flow through the Ethereum block production ecosystem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate block counts per entity\n",
        "entity_block_counts = df_proposer_blobs.groupby(\"proposer_entity\").size()\n",
        "valid_entities = entity_block_counts[entity_block_counts >= MIN_BLOCKS].index\n",
        "\n",
        "# Filter the dataframe\n",
        "df_filtered = df_proposer_blobs[df_proposer_blobs[\"proposer_entity\"].isin(valid_entities)]\n",
        "\n",
        "# Aggregate flows: entity -> relay\n",
        "entity_relay_flow = (\n",
        "    df_filtered.groupby([\"proposer_entity\", \"winning_relay\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"block_count\")\n",
        ")\n",
        "\n",
        "# Aggregate flows: relay -> blob_count\n",
        "relay_blob_flow = (\n",
        "    df_filtered.groupby([\"winning_relay\", \"blob_count\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"block_count\")\n",
        ")\n",
        "\n",
        "# Sort entities by total block count (descending)\n",
        "entity_totals = entity_relay_flow.groupby(\"proposer_entity\")[\"block_count\"].sum()\n",
        "entities = entity_totals.sort_values(ascending=False).index.tolist()\n",
        "\n",
        "# Sort relays by total block count (descending)\n",
        "relay_totals = relay_blob_flow.groupby(\"winning_relay\")[\"block_count\"].sum()\n",
        "relays = relay_totals.sort_values(ascending=False).index.tolist()\n",
        "\n",
        "blob_counts = sorted(df_filtered[\"blob_count\"].unique(), reverse=True)  # Descending\n",
        "\n",
        "# Create node labels: entities + relays + blob counts\n",
        "entity_nodes = [f\"E:{e}\" for e in entities]\n",
        "relay_nodes = [f\"R:{r}\" for r in relays]\n",
        "blob_nodes = [f\"{int(bc)} blobs\" for bc in blob_counts]\n",
        "all_nodes = entity_nodes + relay_nodes + blob_nodes\n",
        "\n",
        "# Create mapping from name to index\n",
        "node_map = {name: idx for idx, name in enumerate(all_nodes)}\n",
        "\n",
        "# Define x and y positions for nodes (3 columns)\n",
        "n_entities = len(entity_nodes)\n",
        "n_relays = len(relay_nodes)\n",
        "n_blobs = len(blob_nodes)\n",
        "\n",
        "entity_colors = [pc.qualitative.Plotly[i % len(pc.qualitative.Plotly)] for i in range(n_entities)]\n",
        "relay_colors = [pc.qualitative.Pastel[i % len(pc.qualitative.Pastel)] for i in range(n_relays)]\n",
        "max_blob = max(blob_counts)\n",
        "min_blob = min(blob_counts)\n",
        "blob_colors = [\n",
        "    pc.sample_colorscale(\"Amp\", (bc - min_blob) / (max_blob - min_blob) if max_blob > min_blob else 0.5)[0]\n",
        "    for bc in blob_counts\n",
        "]\n",
        "\n",
        "x_pos = []\n",
        "y_pos = []\n",
        "\n",
        "# Entity nodes on the left (x=0.01)\n",
        "for i in range(n_entities):\n",
        "    x_pos.append(0.01)\n",
        "    y_pos.append((i + 0.5) / n_entities)\n",
        "\n",
        "# Relay nodes in the middle (x=0.5)\n",
        "for i in range(n_relays):\n",
        "    x_pos.append(0.5)\n",
        "    y_pos.append((i + 0.5) / n_relays)\n",
        "\n",
        "# Blob count nodes on the right (x=0.99)\n",
        "for i in range(n_blobs):\n",
        "    x_pos.append(0.99)\n",
        "    y_pos.append((i + 0.5) / n_blobs)\n",
        "\n",
        "sources = []\n",
        "targets = []\n",
        "values = []\n",
        "\n",
        "# Entity -> Relay links\n",
        "for _, row in entity_relay_flow.iterrows():\n",
        "    e_node = f\"E:{row['proposer_entity']}\"\n",
        "    r_node = f\"R:{row['winning_relay']}\"\n",
        "    if e_node in node_map and r_node in node_map:\n",
        "        sources.append(node_map[e_node])\n",
        "        targets.append(node_map[r_node])\n",
        "        values.append(row[\"block_count\"])\n",
        "\n",
        "# Relay -> Blob count links\n",
        "for _, row in relay_blob_flow.iterrows():\n",
        "    r_node = f\"R:{row['winning_relay']}\"\n",
        "    bc_node = f\"{int(row['blob_count'])} blobs\"\n",
        "    if r_node in node_map and bc_node in node_map:\n",
        "        sources.append(node_map[r_node])\n",
        "        targets.append(node_map[bc_node])\n",
        "        values.append(row[\"block_count\"])\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Sankey(\n",
        "            arrangement=\"snap\",\n",
        "            node=dict(\n",
        "                pad=15,\n",
        "                thickness=30,\n",
        "                line=dict(color=\"black\", width=0.5),\n",
        "                label=all_nodes,\n",
        "                x=x_pos,\n",
        "                y=y_pos,\n",
        "                color=entity_colors + relay_colors + blob_colors,\n",
        "            ),\n",
        "            link=dict(source=sources, target=targets, value=values),\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "fig.update_layout(\n",
        "    title=f\"Blob flow: Proposer Entity -> Relay -> Blob Count (min {MIN_BLOCKS} blocks)\",\n",
        "    font_size=12,\n",
        "    width=800,\n",
        "    height=3500,\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}